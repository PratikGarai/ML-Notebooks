{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP 0toH.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-drwSu6-LOWk"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbL0GfAQLrxx"
      },
      "source": [
        "sentences = [\r\n",
        "             'I love my dog',\r\n",
        "             'I love my cat',\r\n",
        "             'There is a dog on the street!'\r\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_50smxSLzRs",
        "outputId": "6f7e88eb-2c96-4a69-99bd-3651d084f8ab"
      },
      "source": [
        "# Create a tokenizer with max 100 words and train them on a list of sentence\r\n",
        "# Print the word:index dictionary generated by them\r\n",
        "\r\n",
        "tokenizer = Tokenizer(num_words=100, oov_token='<OOV>')\r\n",
        "tokenizer.fit_on_texts(sentences)\r\n",
        "word_index = tokenizer.word_index\r\n",
        "print(word_index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'<OOV>': 1, 'i': 2, 'love': 3, 'my': 4, 'dog': 5, 'cat': 6, 'there': 7, 'is': 8, 'a': 9, 'on': 10, 'the': 11, 'street': 12}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SgH-Tq78MFhl",
        "outputId": "24bde907-22f0-4459-fc80-350dc59df266"
      },
      "source": [
        "# Convert sentences into list of indexes\r\n",
        "\r\n",
        "sequences = tokenizer.texts_to_sequences(sentences)\r\n",
        "for i in sequences:\r\n",
        "  print(i)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2, 3, 4, 5]\n",
            "[2, 3, 4, 6]\n",
            "[7, 8, 9, 5, 10, 11, 12]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQL-vBeYNSZD",
        "outputId": "bcf1b9cf-a104-45ed-cdb3-e227523fbca0"
      },
      "source": [
        "# Now, reverse convert words which weren't in the vocabulory\r\n",
        "# things that weren't in vocabulory are termed as OOV\r\n",
        "new_sentences = [\r\n",
        "                 'Hi! My dog is Tommy',\r\n",
        "                 'My dog love bones'\r\n",
        "]\r\n",
        "\r\n",
        "new_sequences = tokenizer.texts_to_sequences(new_sentences)\r\n",
        "for i in new_sequences:\r\n",
        "  print(i)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 4, 5, 8, 1]\n",
            "[4, 5, 3, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7J05sXjDRO9b",
        "outputId": "67cb241e-70f7-47b4-a35f-a349682c358e"
      },
      "source": [
        "# for training purpose, we need sentences of same length\r\n",
        "# so we need to pad them with stuff\r\n",
        "\r\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\r\n",
        "\r\n",
        "print(\"Un-padded: \")\r\n",
        "for i in sequences :\r\n",
        "  print(i)\r\n",
        "\r\n",
        "print(\"\\nPadded: \")\r\n",
        "padded = pad_sequences(sequences)\r\n",
        "for i in padded :\r\n",
        "  print(i)\r\n",
        "\r\n",
        "# sentences get pre-padded with a special '0' index \r\n",
        "# and get converted to numpy array from list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Un-padded: \n",
            "[2, 3, 4, 5]\n",
            "[2, 3, 4, 6]\n",
            "[7, 8, 9, 5, 10, 11, 12]\n",
            "\n",
            "Padded: \n",
            "[0 0 0 2 3 4 5]\n",
            "[0 0 0 2 3 4 6]\n",
            "[ 7  8  9  5 10 11 12]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggtF0LFfSqSe",
        "outputId": "d1c68165-53c2-4daf-dcb1-e7b03ea402f6"
      },
      "source": [
        "# some other ways of padding \r\n",
        "\r\n",
        "# Padding on the end of string\r\n",
        "padded = pad_sequences(sequences, padding='post')\r\n",
        "for i in padded :\r\n",
        "  print(i)\r\n",
        "print(\"\\n\")\r\n",
        "\r\n",
        "# put a maximum length from back\r\n",
        "padded = pad_sequences(sequences, maxlen=5)\r\n",
        "for i in padded :\r\n",
        "  print(i)\r\n",
        "print(\"\\n\")\r\n",
        "\r\n",
        "# put a maximum length from front\r\n",
        "padded = pad_sequences(sequences, maxlen=5, truncating='post')\r\n",
        "for i in padded :\r\n",
        "  print(i)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2 3 4 5 0 0 0]\n",
            "[2 3 4 6 0 0 0]\n",
            "[ 7  8  9  5 10 11 12]\n",
            "\n",
            "\n",
            "[0 2 3 4 5]\n",
            "[0 2 3 4 6]\n",
            "[ 9  5 10 11 12]\n",
            "\n",
            "\n",
            "[0 2 3 4 5]\n",
            "[0 2 3 4 6]\n",
            "[ 7  8  9  5 10]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "geZSebdETtjv"
      },
      "source": [
        "# padding\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "# padding"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVMm2ayFdWoy",
        "outputId": "2bdf61de-00cc-49ef-f9f4-ded528c8ce55"
      },
      "source": [
        "# getting our file\r\n",
        "!wget --no-check-certificate \\\r\n",
        "    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/sarcasm.json \\\r\n",
        "    -O /tmp/sarcasm.json"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-02-14 12:36:33--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/sarcasm.json\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.137.128, 142.250.101.128, 2607:f8b0:4023:c03::80, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.137.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5643545 (5.4M) [application/json]\n",
            "Saving to: ‘/tmp/sarcasm.json’\n",
            "\n",
            "/tmp/sarcasm.json   100%[===================>]   5.38M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2021-02-14 12:36:34 (52.7 MB/s) - ‘/tmp/sarcasm.json’ saved [5643545/5643545]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFPnnaw_dpWG"
      },
      "source": [
        "import json\r\n",
        "\r\n",
        "datastore = None\r\n",
        "with open(\"/tmp/sarcasm.json\", 'r') as f:\r\n",
        "    datastore = json.load(f)\r\n",
        "\r\n",
        "sentences = []\r\n",
        "labels = []\r\n",
        "\r\n",
        "for item in datastore:\r\n",
        "    sentences.append(item['headline'])\r\n",
        "    labels.append(item['is_sarcastic'])\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2Of5zWaeBai",
        "outputId": "063bf781-d437-4426-e006-24bfab384911"
      },
      "source": [
        "print(type(datastore))\r\n",
        "print(datastore[0])\r\n",
        "print(datastore[2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'list'>\n",
            "{'article_link': 'https://www.huffingtonpost.com/entry/versace-black-code_us_5861fbefe4b0de3a08f600d5', 'headline': \"former versace store clerk sues over secret 'black code' for minority shoppers\", 'is_sarcastic': 0}\n",
            "{'article_link': 'https://local.theonion.com/mom-starting-to-fear-son-s-web-series-closest-thing-she-1819576697', 'headline': \"mom starting to fear son's web series closest thing she will have to grandchild\", 'is_sarcastic': 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1ILMt3-eDE7",
        "outputId": "62e60e29-5d26-4d8f-8126-1125b5422ef2"
      },
      "source": [
        "len(sentences)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26709"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmNC_ZJRecmS"
      },
      "source": [
        "tokenizer = Tokenizer(oov_token='<OOV>')\r\n",
        "tokenizer.fit_on_texts(sentences)\r\n",
        "word_index = tokenizer.word_index\r\n",
        "\r\n",
        "sequences = tokenizer.texts_to_sequences(sentences)\r\n",
        "padded = pad_sequences(sequences, padding='post')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjkBPSd1md5b",
        "outputId": "1fbac1ef-8e49-464d-960e-44bcd474d830"
      },
      "source": [
        "print(padded[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[  308 15115   679  3337  2298    48   382  2576 15116     6  2577  8434\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_fxaiQFUmf2p",
        "outputId": "491e032a-bc3d-4d41-cf64-d105db0984dc"
      },
      "source": [
        "print(padded.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(26709, 40)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9paQthrbmjgD"
      },
      "source": [
        "# PADDING\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "# PADDING"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VmMoCg74m5Rw"
      },
      "source": [
        "train_size = 20000\r\n",
        "max_length = 15\r\n",
        "max_words = 20000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOG524zg6PPh"
      },
      "source": [
        "trainX = sentences[:train_size]\r\n",
        "testX = sentences[train_size:]\r\n",
        "\r\n",
        "trainY = labels[:train_size]\r\n",
        "testY = labels[train_size:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSPr7iuK-j02"
      },
      "source": [
        "tokenizer = Tokenizer(oov_token='<OOV>', num_words = max_words)\r\n",
        "tokenizer.fit_on_texts(trainX)\r\n",
        "\r\n",
        "word_index = tokenizer.word_index\r\n",
        "\r\n",
        "trainS = tokenizer.texts_to_sequences(trainX)\r\n",
        "testS = tokenizer.texts_to_sequences(testX)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_xc7kmMj_lg"
      },
      "source": [
        "padTrain = pad_sequences(trainS, maxlen=max_length, padding='post', truncating='post')\r\n",
        "padTest = pad_sequences(testS, maxlen=max_length, padding='post', truncating='post')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvmI-ozrkFDC",
        "outputId": "1a3656d5-d170-4a31-aa67-bedb60a06807"
      },
      "source": [
        "print(padTest[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[17706  1100  6663  9423    30 11505  2439     5   519   109     0     0\n",
            "     0     0     0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVm3a5Buk6EX"
      },
      "source": [
        "# model creation \r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "model = tf.keras.Sequential([\r\n",
        "                             tf.keras.layers.Embedding(max_words, 16, input_length=max_length),\r\n",
        "                             tf.keras.layers.GlobalAveragePooling1D(),\r\n",
        "                             tf.keras.layers.Dense(24, activation='relu'),\r\n",
        "                             tf.keras.layers.Dense(1, activation='sigmoid')\r\n",
        "])\r\n",
        "\r\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvhzhEjUmJvK",
        "outputId": "b1933fd4-9cd8-4537-f2bb-9cba5703285c"
      },
      "source": [
        "import numpy as np\r\n",
        "\r\n",
        "model.fit(padTrain, np.array(trainY), epochs=15, validation_data=(padTest, np.array(testY)), verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.6026 - accuracy: 0.6632 - val_loss: 0.3566 - val_accuracy: 0.8508\n",
            "Epoch 2/15\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.2594 - accuracy: 0.8994 - val_loss: 0.3392 - val_accuracy: 0.8554\n",
            "Epoch 3/15\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.1530 - accuracy: 0.9468 - val_loss: 0.3778 - val_accuracy: 0.8469\n",
            "Epoch 4/15\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.0997 - accuracy: 0.9680 - val_loss: 0.4217 - val_accuracy: 0.8518\n",
            "Epoch 5/15\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.0614 - accuracy: 0.9838 - val_loss: 0.4910 - val_accuracy: 0.8425\n",
            "Epoch 6/15\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.0398 - accuracy: 0.9904 - val_loss: 0.5721 - val_accuracy: 0.8380\n",
            "Epoch 7/15\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.0298 - accuracy: 0.9925 - val_loss: 0.6533 - val_accuracy: 0.8328\n",
            "Epoch 8/15\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.0189 - accuracy: 0.9960 - val_loss: 0.7374 - val_accuracy: 0.8264\n",
            "Epoch 9/15\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.0119 - accuracy: 0.9978 - val_loss: 0.8283 - val_accuracy: 0.8258\n",
            "Epoch 10/15\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.0078 - accuracy: 0.9987 - val_loss: 0.9269 - val_accuracy: 0.8240\n",
            "Epoch 11/15\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.0051 - accuracy: 0.9991 - val_loss: 1.0035 - val_accuracy: 0.8193\n",
            "Epoch 12/15\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.0024 - accuracy: 0.9997 - val_loss: 1.0969 - val_accuracy: 0.8168\n",
            "Epoch 13/15\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.1706 - val_accuracy: 0.8168\n",
            "Epoch 14/15\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.0013 - accuracy: 0.9999 - val_loss: 1.2590 - val_accuracy: 0.8176\n",
            "Epoch 15/15\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 6.7579e-04 - accuracy: 0.9999 - val_loss: 1.3371 - val_accuracy: 0.8183\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa67daee6d8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20JzP65bqSeW"
      },
      "source": [
        "# time to test it out!!!!\r\n",
        "\r\n",
        "test_sentences = [\r\n",
        "                  'granny starting to fear that spiders in the garden might be real',\r\n",
        "                  'the weather today is bright and sunny'\r\n",
        "]\r\n",
        "\r\n",
        "sequences = tokenizer.texts_to_sequences(test_sentences)\r\n",
        "padded = pad_sequences(sequences, maxlen=max_length, padding='post', truncating='post')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gm3LiqpWsUec"
      },
      "source": [
        "preds = model.predict(padded)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-c-XnptuuCDM",
        "outputId": "f2788945-9579-417f-cc4c-f04158cb8e3d"
      },
      "source": [
        "for i in range(2):\r\n",
        "  print(test_sentences[i])\r\n",
        "  if preds[i]>=0.5 :\r\n",
        "    print(\"- Sarcastic\\n\")\r\n",
        "  else :\r\n",
        "    print(\"- Not Sarcastic\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "granny starting to fear that spiders in the garden might be real\n",
            "- Sarcastic\n",
            "\n",
            "the weather today is bright and sunny\n",
            "- Not Sarcastic\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mowWg1Z1uYHW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
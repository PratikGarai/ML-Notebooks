{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-drwSu6-LOWk"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YbL0GfAQLrxx"
   },
   "outputs": [],
   "source": [
    "sentences = [\n",
    "             'I love my dog',\n",
    "             'I love my cat',\n",
    "             'There is a dog on the street!'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B_50smxSLzRs",
    "outputId": "6f7e88eb-2c96-4a69-99bd-3651d084f8ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<OOV>': 1, 'i': 2, 'love': 3, 'my': 4, 'dog': 5, 'cat': 6, 'there': 7, 'is': 8, 'a': 9, 'on': 10, 'the': 11, 'street': 12}\n"
     ]
    }
   ],
   "source": [
    "# Create a tokenizer with max 100 words and train them on a list of sentence\n",
    "# Print the word:index dictionary generated by them\n",
    "\n",
    "tokenizer = Tokenizer(num_words=100, oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "word_index = tokenizer.word_index\n",
    "print(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SgH-Tq78MFhl",
    "outputId": "24bde907-22f0-4459-fc80-350dc59df266"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 4, 5]\n",
      "[2, 3, 4, 6]\n",
      "[7, 8, 9, 5, 10, 11, 12]\n"
     ]
    }
   ],
   "source": [
    "# Convert sentences into list of indexes\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(sentences)\n",
    "for i in sequences:\n",
    "  print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mQL-vBeYNSZD",
    "outputId": "bcf1b9cf-a104-45ed-cdb3-e227523fbca0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4, 5, 8, 1]\n",
      "[4, 5, 3, 1]\n"
     ]
    }
   ],
   "source": [
    "# Now, reverse convert words which weren't in the vocabulory\n",
    "# things that weren't in vocabulory are termed as OOV\n",
    "new_sentences = [\n",
    "                 'Hi! My dog is Tommy',\n",
    "                 'My dog love bones'\n",
    "]\n",
    "\n",
    "new_sequences = tokenizer.texts_to_sequences(new_sentences)\n",
    "for i in new_sequences:\n",
    "  print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7J05sXjDRO9b",
    "outputId": "67cb241e-70f7-47b4-a35f-a349682c358e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Un-padded: \n",
      "[2, 3, 4, 5]\n",
      "[2, 3, 4, 6]\n",
      "[7, 8, 9, 5, 10, 11, 12]\n",
      "\n",
      "Padded: \n",
      "[0 0 0 2 3 4 5]\n",
      "[0 0 0 2 3 4 6]\n",
      "[ 7  8  9  5 10 11 12]\n"
     ]
    }
   ],
   "source": [
    "# for training purpose, we need sentences of same length\n",
    "# so we need to pad them with stuff\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "print(\"Un-padded: \")\n",
    "for i in sequences :\n",
    "  print(i)\n",
    "\n",
    "print(\"\\nPadded: \")\n",
    "padded = pad_sequences(sequences)\n",
    "for i in padded :\n",
    "  print(i)\n",
    "\n",
    "# sentences get pre-padded with a special '0' index \n",
    "# and get converted to numpy array from list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ggtF0LFfSqSe",
    "outputId": "d1c68165-53c2-4daf-dcb1-e7b03ea402f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 3 4 5 0 0 0]\n",
      "[2 3 4 6 0 0 0]\n",
      "[ 7  8  9  5 10 11 12]\n",
      "\n",
      "\n",
      "[0 2 3 4 5]\n",
      "[0 2 3 4 6]\n",
      "[ 9  5 10 11 12]\n",
      "\n",
      "\n",
      "[0 2 3 4 5]\n",
      "[0 2 3 4 6]\n",
      "[ 7  8  9  5 10]\n"
     ]
    }
   ],
   "source": [
    "# some other ways of padding \n",
    "\n",
    "# Padding on the end of string\n",
    "padded = pad_sequences(sequences, padding='post')\n",
    "for i in padded :\n",
    "  print(i)\n",
    "print(\"\\n\")\n",
    "\n",
    "# put a maximum length from back\n",
    "padded = pad_sequences(sequences, maxlen=5)\n",
    "for i in padded :\n",
    "  print(i)\n",
    "print(\"\\n\")\n",
    "\n",
    "# put a maximum length from front\n",
    "padded = pad_sequences(sequences, maxlen=5, truncating='post')\n",
    "for i in padded :\n",
    "  print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "geZSebdETtjv"
   },
   "outputs": [],
   "source": [
    "# padding\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RVMm2ayFdWoy",
    "outputId": "2bdf61de-00cc-49ef-f9f4-ded528c8ce55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-02-14 12:36:33--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/sarcasm.json\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.137.128, 142.250.101.128, 2607:f8b0:4023:c03::80, ...\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.137.128|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 5643545 (5.4M) [application/json]\n",
      "Saving to: ‘/tmp/sarcasm.json’\n",
      "\n",
      "/tmp/sarcasm.json   100%[===================>]   5.38M  --.-KB/s    in 0.1s    \n",
      "\n",
      "2021-02-14 12:36:34 (52.7 MB/s) - ‘/tmp/sarcasm.json’ saved [5643545/5643545]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# getting our file\n",
    "!wget --no-check-certificate \\\n",
    "    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/sarcasm.json \\\n",
    "    -O /tmp/sarcasm.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QFPnnaw_dpWG"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "datastore = None\n",
    "with open(\"/tmp/sarcasm.json\", 'r') as f:\n",
    "    datastore = json.load(f)\n",
    "\n",
    "sentences = []\n",
    "labels = []\n",
    "\n",
    "for item in datastore:\n",
    "    sentences.append(item['headline'])\n",
    "    labels.append(item['is_sarcastic'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G2Of5zWaeBai",
    "outputId": "063bf781-d437-4426-e006-24bfab384911"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "{'article_link': 'https://www.huffingtonpost.com/entry/versace-black-code_us_5861fbefe4b0de3a08f600d5', 'headline': \"former versace store clerk sues over secret 'black code' for minority shoppers\", 'is_sarcastic': 0}\n",
      "{'article_link': 'https://local.theonion.com/mom-starting-to-fear-son-s-web-series-closest-thing-she-1819576697', 'headline': \"mom starting to fear son's web series closest thing she will have to grandchild\", 'is_sarcastic': 1}\n"
     ]
    }
   ],
   "source": [
    "print(type(datastore))\n",
    "print(datastore[0])\n",
    "print(datastore[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h1ILMt3-eDE7",
    "outputId": "62e60e29-5d26-4d8f-8126-1125b5422ef2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26709"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RmNC_ZJRecmS"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(sentences)\n",
    "padded = pad_sequences(sequences, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CjkBPSd1md5b",
    "outputId": "1fbac1ef-8e49-464d-960e-44bcd474d830"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  308 15115   679  3337  2298    48   382  2576 15116     6  2577  8434\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0]\n"
     ]
    }
   ],
   "source": [
    "print(padded[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_fxaiQFUmf2p",
    "outputId": "491e032a-bc3d-4d41-cf64-d105db0984dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26709, 40)\n"
     ]
    }
   ],
   "source": [
    "print(padded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9paQthrbmjgD"
   },
   "outputs": [],
   "source": [
    "# PADDING\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# PADDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VmMoCg74m5Rw"
   },
   "outputs": [],
   "source": [
    "train_size = 20000\n",
    "max_length = 15\n",
    "max_words = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IOG524zg6PPh"
   },
   "outputs": [],
   "source": [
    "trainX = sentences[:train_size]\n",
    "testX = sentences[train_size:]\n",
    "\n",
    "trainY = labels[:train_size]\n",
    "testY = labels[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OSPr7iuK-j02"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(oov_token='<OOV>', num_words = max_words)\n",
    "tokenizer.fit_on_texts(trainX)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "trainS = tokenizer.texts_to_sequences(trainX)\n",
    "testS = tokenizer.texts_to_sequences(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n_xc7kmMj_lg"
   },
   "outputs": [],
   "source": [
    "padTrain = pad_sequences(trainS, maxlen=max_length, padding='post', truncating='post')\n",
    "padTest = pad_sequences(testS, maxlen=max_length, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lvmI-ozrkFDC",
    "outputId": "1a3656d5-d170-4a31-aa67-bedb60a06807"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17706  1100  6663  9423    30 11505  2439     5   519   109     0     0\n",
      "     0     0     0]\n"
     ]
    }
   ],
   "source": [
    "print(padTest[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MVm3a5Buk6EX"
   },
   "outputs": [],
   "source": [
    "# model creation \n",
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "                             tf.keras.layers.Embedding(max_words, 16, input_length=max_length),\n",
    "                             tf.keras.layers.GlobalAveragePooling1D(),\n",
    "                             tf.keras.layers.Dense(24, activation='relu'),\n",
    "                             tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OvhzhEjUmJvK",
    "outputId": "b1933fd4-9cd8-4537-f2bb-9cba5703285c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.6026 - accuracy: 0.6632 - val_loss: 0.3566 - val_accuracy: 0.8508\n",
      "Epoch 2/15\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.2594 - accuracy: 0.8994 - val_loss: 0.3392 - val_accuracy: 0.8554\n",
      "Epoch 3/15\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.1530 - accuracy: 0.9468 - val_loss: 0.3778 - val_accuracy: 0.8469\n",
      "Epoch 4/15\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.0997 - accuracy: 0.9680 - val_loss: 0.4217 - val_accuracy: 0.8518\n",
      "Epoch 5/15\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.0614 - accuracy: 0.9838 - val_loss: 0.4910 - val_accuracy: 0.8425\n",
      "Epoch 6/15\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.0398 - accuracy: 0.9904 - val_loss: 0.5721 - val_accuracy: 0.8380\n",
      "Epoch 7/15\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.0298 - accuracy: 0.9925 - val_loss: 0.6533 - val_accuracy: 0.8328\n",
      "Epoch 8/15\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.0189 - accuracy: 0.9960 - val_loss: 0.7374 - val_accuracy: 0.8264\n",
      "Epoch 9/15\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.0119 - accuracy: 0.9978 - val_loss: 0.8283 - val_accuracy: 0.8258\n",
      "Epoch 10/15\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.0078 - accuracy: 0.9987 - val_loss: 0.9269 - val_accuracy: 0.8240\n",
      "Epoch 11/15\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.0051 - accuracy: 0.9991 - val_loss: 1.0035 - val_accuracy: 0.8193\n",
      "Epoch 12/15\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.0024 - accuracy: 0.9997 - val_loss: 1.0969 - val_accuracy: 0.8168\n",
      "Epoch 13/15\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.1706 - val_accuracy: 0.8168\n",
      "Epoch 14/15\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.0013 - accuracy: 0.9999 - val_loss: 1.2590 - val_accuracy: 0.8176\n",
      "Epoch 15/15\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 6.7579e-04 - accuracy: 0.9999 - val_loss: 1.3371 - val_accuracy: 0.8183\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa67daee6d8>"
      ]
     },
     "execution_count": 86,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "model.fit(padTrain, np.array(trainY), epochs=15, validation_data=(padTest, np.array(testY)), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "20JzP65bqSeW"
   },
   "outputs": [],
   "source": [
    "# time to test it out!!!!\n",
    "\n",
    "test_sentences = [\n",
    "                  'granny starting to fear that spiders in the garden might be real',\n",
    "                  'the weather today is bright and sunny'\n",
    "]\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(test_sentences)\n",
    "padded = pad_sequences(sequences, maxlen=max_length, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gm3LiqpWsUec"
   },
   "outputs": [],
   "source": [
    "preds = model.predict(padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-c-XnptuuCDM",
    "outputId": "f2788945-9579-417f-cc4c-f04158cb8e3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "granny starting to fear that spiders in the garden might be real\n",
      "- Sarcastic\n",
      "\n",
      "the weather today is bright and sunny\n",
      "- Not Sarcastic\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "  print(test_sentences[i])\n",
    "  if preds[i]>=0.5 :\n",
    "    print(\"- Sarcastic\\n\")\n",
    "  else :\n",
    "    print(\"- Not Sarcastic\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mowWg1Z1uYHW"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "NLP 0toH.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
